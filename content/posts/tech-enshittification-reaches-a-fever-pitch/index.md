---
title: "Tech Enshittification Reaches a Fever Pitch"
date: 2025-05-02T15:19:12-04:00
---

The enshittification of the tech industry is reaching a fever pitch, and it's
all thanks to AI. Not what AI can do, but what people seem to *think* it can do.

It's really hard to get a job in tech right now. Surely our industry has gone
through its ups and downs and hiring waxes and wanes alongside interest rates
and how sweaty the many perpetually damp men in the Silicon Valley VC scene are
on a given day. But things are getting rough out there, friends.

<!--more-->

I always hesitate to use the overused term "perfect storm," but maybe this is
one. Interest rates are high, VCs are less emboldened (unless your pitch has
something to do with AI or the blockchain), and there is this massive shared
hallucination that generative AI is going to allow a company to do everything it
currently does, at the same or better levels of quality, with a quarter of the
staff.

So certain are the grasping capitalists that this narrative is true that they're
firing people in droves. All of these talented people suddenly entering the job
market alongside this assuredly false belief that they won't be needed has
created an imbalance in the market. Too many tech workers, too few tech jobs.

But what's really happening here is *enshittification*.

Cory Doctorow coined the term "enshittification" for this phenomenon where a
company locks in a consumer audience with unrealistically good prices (typically
subsidized by VC), then uses the leverage of a massive and committed consumer
audience to lock in suppliers. It is at this point where all the benefits begin
to be shaved away. First the prices go up for consumers, then the payouts go
down for suppliers. Amazon is so good at this that they're in multiple federal
lawsuits about it.

The enshittification of the tech industry is similar. Employers like Google and
Netflix realized how much leverage they could get with great software talent, so
they pampered the shit out of these kids with Michelin Star chefs and on-site
laundry. Eventually their products became the defaults (the market share of
Google as a search engine is still over 90%, an absurd winning streak for a
search service that's getting gradually worse).

Once the audience was locked in and the cash was free-flowing, they could start
taking the screws to the employees. Maybe there's still a barista in every
kitchen, but it's "come back to the office five days a week" and "your weekly
target should be about 60 hours of work" (said Sergey Brin recently, a man who
just completed his slow-motion transformation into a sociopathic ghoul).

It is unequivocally the AI *narrative* that is fueling this enshittification.
Not what AI can do, but what leaders *think AI can do*. This narrative has taken
hold for two important reasons: first, there is a seed of truth in it; second,
it is exactly what corporate tech leaders want to hear.

The seed of truth is that generative AI in the programming space has advanced to
a truly usable level in just the last few months. My own work is surely
accelerated by the help of Copilot, which mainly types faster than I do, and
which can convert large swaths of JSON into a similarly large swath of Golang
structs faster than I can... But it's not really *solving any problems*. Copilot
dramatically reduces the length of the "search StackOverflow, identify the
accepted solution, copy and paste the code" loop.

Tools like Cursor and Windsurf might be even more effective, but ultimately AI
can only patch together fragments of stuff it's already seen, which has a really
high degree of utility when building prototypes, but can't solve any of the
problems that only become problems when you actually succeed at something and
face real competition.

To the extent that the "StackOverflow copy/paste loop" is at least half of the
job, it's very helpful! But it can't replace me, because it can't understand
what PMs are really asking for, or what customers might actually want but don't
know how to ask for.

But the real cutting edge of this AI narrative is the second bit: it's the story
that these lonely, grasping, soulless, fragile male egos desperately want to
tell. Mark Zuckerberg was probably as worked up as a nun in a cucumber patch
when he got to tell his board of directors that he'll be able to lay off
thousands of pampered nerds and still produce the same output.

It's a great story. It somehow survives scrutiny, at least from those with no
hands-on experience. Some of the facts line up enough to suggest that it could
work out. But... It won't. It can't.

Amazon is similarly using AI as an excuse to "flatten the organization," which
is a business euphemism for firing capable managers and forcing the rest to
manage 30+ people each. Google tried that once and it was a spectacular failure,
so I doubt AI is going to magically fix it. If you think it's bad reporting to a
hurried, burned-out, frantic manager, try reporting to ChatGPT. AI may seem
patient but what it really is is relentless and confidently wrong a lot of the
time.

You know what else is relentless and confidently wrong a lot of the time?
Ego-drunk sociopaths. It's like if every single engineer at Amazon suddenly
reported directly to Jeff Bezos, a man who seems mainly concerned with how often
he can get his shirt off to make sure you know how much hair he has under there.
Gross. You're gross, Jeffrey.

The light at the end of the tunnel is that this mass hallucination is just that:
a hallucination. Maybe AI will fill in the gaps enough that juggernauts like
Amazon can continue adding endpoints to their AWS APIs and only burn out 1,000
engineers instead of 10,000, but mark my words: the gravy train will jump the
tracks eventually.

Just as the dot com bubble burst, and as the blockchain proved to be useful only to
buy drugs and gamble, this AI "dream" will evaporate and companies will be stuck
wondering why all of the products they are building seem to be regressing to
some uninspiring mean.

Keep your heads up, friends.
